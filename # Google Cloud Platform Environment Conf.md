# Google Cloud Platform Environment Configuration# YouAndINotAI Dating Platform# Project: elevated-module-462113-f0# NOTE: These are reference values only.# Actual secrets are stored in GCP Secret Manager.# Cloud Run automatically injects secrets as environment variables.# ============================================================================# APPLICATION# ============================================================================NODE_ENV=productionPORT=3000# ============================================================================# GOOGLE CLOUD PROJECT# ============================================================================GCP_PROJECT_ID=elevated-module-462113-f0GCP_REGION=us-central1# ============================================================================# DATABASE (Cloud SQL PostgreSQL 16)# ============================================================================# Cloud Run uses Unix socket connection via /cloudsql/DATABASE_HOST=/cloudsql/elevated-module-462113-f0:us-central1:youandinotai-dbDATABASE_NAME=youandinotai_prodDATABASE_USER=youandinotai_userDATABASE_PASSWORD=secret:db-password  # Injected from Secret ManagerDATABASE_PORT=5432# Alternative TCP connection (for local development with Cloud SQL Proxy):# DATABASE_HOST=localhost# DATABASE_PORT=5432# ============================================================================# REDIS (Memorystore)# ============================================================================# Injected by deployment scriptREDIS_HOST=10.x.x.x  # Private IP from MemorystoreREDIS_PORT=6379REDIS_URL=redis://${REDIS_HOST}:${REDIS_PORT}# ============================================================================# SQUARE PAYMENT (LIVE Production)# ============================================================================SQUARE_ENVIRONMENT=productionSQUARE_ACCESS_TOKEN=secret:square-token  # Injected from Secret ManagerSQUARE_APP_ID=sq0idp-Carv59GQKuQHoIydJ1WanwSQUARE_LOCATION_ID=LHPBX0P3TBTEC# ============================================================================# GEMINI AI (Native GCP Integration)# ============================================================================GEMINI_API_KEY=secret:gemini-api-key  # Injected from Secret ManagerGEMINI_MODEL=gemini-pro# ============================================================================# MANUS AI (Task Automation)# ============================================================================MANUS_API_KEY=YOUR_MANUS_API_KEY_HERE  # Update in Secret ManagerMANUS_API_URL=https://api.manus.ai/v1# ============================================================================# AZURE COGNITIVE SERVICES (Human Verification)# ============================================================================AZURE_COGNITIVE_KEY=secret:azure-cognitive-key  # Injected from Secret ManagerAZURE_COGNITIVE_ENDPOINT=https://eastus.api.cognitive.microsoft.com# ============================================================================# JWT AUTHENTICATION# ============================================================================JWT_SECRET=secret:jwt-secret  # Injected from Secret ManagerJWT_REFRESH_SECRET=secret:jwt-refresh-secret  # Injected from Secret ManagerJWT_EXPIRES_IN=15mJWT_REFRESH_EXPIRES_IN=7d# ============================================================================# CLOUD RUN SPECIFIC# ============================================================================# These are automatically set by Cloud Run:# K_SERVICE - Service name# K_REVISION - Revision name# K_CONFIGURATION - Configuration name# PORT - Port to listen on (injected by Cloud Run)# ============================================================================# SECRETS STORED IN SECRET MANAGER# ============================================================================# To update a secret:# echo -n "new_value" | gcloud secrets versions add SECRET_NAME --data-file=-## Available secrets:# - db-password# - square-token# - gemini-api-key# - azure-cognitive-key# - jwt-secret# - jwt-refresh-secret# - manus-api-key (add this)# ============================================================================# LOCAL DEVELOPMENT WITH GCP# ============================================================================# To run locally with GCP services:## 1. Start Cloud SQL Proxy:#    ./cloud-sql-proxy elevated-module-462113-f0:us-central1:youandinotai-db## 2. Port forward to Memorystore (via Compute Engine instance):#    gcloud compute ssh redis-forwarder --zone=us-central1-a \#      -- -N -L 6379:REDIS_IP:6379## 3. Get secrets:#    export SQUARE_ACCESS_TOKEN=$(gcloud secrets versions access latest --secret=square-token)#    export GEMINI_API_KEY=$(gcloud secrets versions access latest --secret=gemini-api-key)#    export DATABASE_PASSWORD=$(gcloud secrets versions access latest --secret=db-password)## 4. Run application:#    npm start# ============================================================================# MONITORING & LOGGING# ============================================================================# Cloud Logging automatically captures:# - console.log() -> INFO level# - console.error() -> ERROR level# - console.warn() -> WARNING level## View logs:# gcloud run services logs read youandinotai-backend --region=us-central1# ============================================================================# COST OPTIMIZATION# ============================================================================# Current configuration: ~$54-69/month## To reduce costs:# - Set min-instances=0 (scale to zero when idle)# - Use Cloud CDN to reduce Cloud Run requests# - Enable Cloud SQL automatic storage# - Use sustained use discounts
Collapse file‚ÄéAWS-DEPLOYMENT-GUIDE.md‚ÄéCopy file name to clipboardExpand all lines: AWS-DEPLOYMENT-GUIDE.md+543Lines changed: 543 additions & 0 deletionsDisplay the source diffDisplay the rich diff Load DiffLarge diffs are not rendered by default.
Collapse file‚ÄéCOMPLETE-CODE-SUMMARY.md‚ÄéCopy file name to clipboardExpand all lines: COMPLETE-CODE-SUMMARY.md+679Lines changed: 679 additions & 0 deletionsDisplay the source diffDisplay the rich diff Load DiffLarge diffs are not rendered by default.
Collapse file‚ÄéDEPLOYMENT-STATUS.md‚ÄéCopy file name to clipboardExpand all lines: DEPLOYMENT-STATUS.md+592Lines changed: 592 additions & 0 deletionsDisplay the source diffDisplay the rich diff Load DiffLarge diffs are not rendered by default.
Collapse file‚ÄéDockerfile.gcp‚ÄéCopy file name to clipboard+44Lines changed: 44 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,44 @@# Dockerfile for Google Cloud Run Deployment# YouAndINotAI Dating Platform Backend# Use official Node.js 18 LTS imageFROM node:18-alpine# Install system dependenciesRUN apk add --no-cache \    postgresql-client \    curl \    openssl# Create app directoryWORKDIR /app# Copy package filesCOPY backend/package*.json ./# Install production dependencies onlyRUN npm ci --only=production && npm cache clean --force# Copy application codeCOPY backend/ ./# Create uploads directoryRUN mkdir -p /app/uploads && chmod 777 /app/uploads# Create non-root user for securityRUN addgroup -g 1001 -S nodejs && \    adduser -S nodejs -u 1001 && \    chown -R nodejs:nodejs /app# Switch to non-root userUSER nodejs# Expose port (Cloud Run will set PORT env var)EXPOSE 3000# Health checkHEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \    CMD curl -f http://localhost:3000/health || exit 1# Start commandCMD ["node", "dating-server-complete.js"]
Collapse file‚ÄéGCP-DEPLOYMENT-GUIDE.md‚ÄéCopy file name to clipboardExpand all lines: GCP-DEPLOYMENT-GUIDE.md+864Lines changed: 864 additions & 0 deletionsDisplay the source diffDisplay the rich diff Load DiffLarge diffs are not rendered by default.
Collapse file‚ÄéNEW-REPOSITORY-SETUP.md‚ÄéCopy file name to clipboardExpand all lines: NEW-REPOSITORY-SETUP.md+404Lines changed: 404 additions & 0 deletionsDisplay the source diffDisplay the rich diff Load DiffLarge diffs are not rendered by default.
Collapse file‚ÄéQUICK-DEPLOY-GCP.md‚ÄéCopy file name to clipboard+304Lines changed: 304 additions & 0 deletionsDisplay the source diffDisplay the rich diffOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,304 @@# Quick Deploy to Google Cloud Platform## YouAndINotAI - 5 Minute Deployment**Project:** `elevated-module-462113-f0`**Region:** `us-central1`**Cost:** ~$54-69/month---## ‚ö° Super Quick Start```bash# 1. Clone and navigategit clone https://github.com/Ai-Solutions-Store/YouAndINotAI.gitcd YouAndINotAIgit checkout claude/env-configuration-update-011CUKA3csdQegERzxd2r4RA# 2. Authenticategcloud auth logingcloud config set project elevated-module-462113-f0# 3. Deploy (takes 10-15 minutes)chmod +x deploy-gcp.sh./deploy-gcp.sh# 4. Get your URLgcloud run services describe youandinotai-backend \  --region=us-central1 \  --format='get(status.url)'# Done! üéâ```---## üìã Prerequisites (2 minutes)### macOS/Linux```bash# Install gcloudcurl https://sdk.cloud.google.com | bashexec -l $SHELLgcloud init# Install Docker# macOS:brew install --cask docker# Linux:curl -fsSL https://get.docker.com | sudo sh```### Windows1. Download gcloud: https://cloud.google.com/sdk/docs/install2. Download Docker Desktop: https://www.docker.com/products/docker-desktop---## üöÄ Deployment Steps### Step 1: Verify Project Access```bashgcloud projects describe elevated-module-462113-f0```**Expected:** Project details displayed### Step 2: Enable BillingVisit: https://console.cloud.google.com/billing?project=elevated-module-462113-f0Link to billing account if not already linked.### Step 3: Run Deployment```bash./deploy-gcp.sh```**What happens:**- ‚úÖ Enables 10+ GCP APIs- ‚úÖ Creates Cloud SQL PostgreSQL database- ‚úÖ Creates Memorystore Redis- ‚úÖ Builds and pushes Docker image- ‚úÖ Deploys to Cloud Run- ‚úÖ Stores secrets securely**Time:** 10-15 minutes### Step 4: Initialize Database```bash# Connect via gcloudgcloud sql connect youandinotai-db --user=youandinotai_user# Or get credentials and connect locallyDB_PASS=$(gcloud secrets versions access latest --secret=db-password)# Run schemaPGPASSWORD=$DB_PASS psql \  -h localhost \  -U youandinotai_user \  -d youandinotai_prod \  -f database/schema.sql```**Expected:** "23 tables created"### Step 5: Test Deployment```bash# Get URLSERVICE_URL=$(gcloud run services describe youandinotai-backend \  --region=us-central1 \  --format='get(status.url)')# Test healthcurl $SERVICE_URL/health```**Expected:**```json{  "status": "healthy",  "platform": "YouAndINotAI Dating Platform"}```---## üîß Post-Deployment Tasks### Add Manus API Key```bash# Get your key from: https://manus.ai/dashboard# Add to Secret Managerecho -n "your_manus_api_key" | \  gcloud secrets versions add manus-api-key --data-file=-# Restart Cloud Run to pick up new secretgcloud run services update youandinotai-backend \  --region=us-central1```### Configure Custom Domain```bash# Option 1: Cloud Run domain mappinggcloud run domain-mappings create \  --service=youandinotai-backend \  --domain=youandinotai.com \  --region=us-central1# Then add DNS record:# CNAME: youandinotai.com -> ghs.googlehosted.com```### Set Up Monitoring```bash# View logsgcloud run services logs read youandinotai-backend \  --region=us-central1 \  --follow# Or visit console:# https://console.cloud.google.com/run/detail/us-central1/youandinotai-backend```---## üí∞ Cost Breakdown| Service | Cost/Month ||---------|------------|| Cloud Run (512MB, 1-10 instances) | $10-20 || Cloud SQL (db-f1-micro, 10GB) | $7 || Memorystore Redis (1GB) | $25 || VPC Connector | $8 || Networking | $3-8 || **TOTAL** | **$54-69** |---## üìä Resource URLs**Cloud Run Service:**https://console.cloud.google.com/run/detail/us-central1/youandinotai-backend?project=elevated-module-462113-f0**Cloud SQL:**https://console.cloud.google.com/sql/instances/youandinotai-db?project=elevated-module-462113-f0**Memorystore Redis:**https://console.cloud.google.com/memorystore/redis/locations/us-central1/instances/youandinotai-redis?project=elevated-module-462113-f0**Secret Manager:**https://console.cloud.google.com/security/secret-manager?project=elevated-module-462113-f0**Logs:**https://console.cloud.google.com/logs/query?project=elevated-module-462113-f0---## üêõ Troubleshooting### Deployment fails: "Permission Denied"```bash# Enable required APIsgcloud services enable run.googleapis.com sqladmin.googleapis.com```### Cloud Run returns 503```bash# Check logsgcloud run services logs read youandinotai-backend \  --region=us-central1 \  --limit=50```### Database connection fails```bash# Check Cloud SQL statusgcloud sql instances describe youandinotai-db# Check VPC connectorgcloud compute networks vpc-access connectors describe youandinotai-vpc-connector \  --region=us-central1```---## üîÑ Update Deployment```bash# 1. Make code changes# 2. Rebuild and redeploydocker build -t us-central1-docker.pkg.dev/elevated-module-462113-f0/youandinotai-repo/youandinotai-backend:latest -f Dockerfile.gcp .docker push us-central1-docker.pkg.dev/elevated-module-462113-f0/youandinotai-repo/youandinotai-backend:latest# Cloud Run automatically deploys new image```---## ‚úÖ Deployment Checklist```Pre-Deployment:‚òê gcloud CLI installed‚òê Docker installed‚òê Authenticated to GCP‚òê Project set: elevated-module-462113-f0‚òê Billing enabledDeployment:‚òê Run ./deploy-gcp.sh‚òê Wait 10-15 minutes‚òê Save Cloud Run URLConfiguration:‚òê Initialize database with schema.sql‚òê Add Manus API key‚òê Test health endpoint‚òê Verify API endpointsDomain Setup:‚òê Configure DNS‚òê Map custom domain‚òê Verify SSL certificateMonitoring:‚òê Set up error alerts‚òê Configure log retention‚òê Test scalingGo Live:‚òê Update production DNS‚òê Load testing‚òê Monitor for errors‚òê Celebrate! üéâ```---## üìû Need Help?**Documentation:** `GCP-DEPLOYMENT-GUIDE.md` (comprehensive guide)**GCP Console:** https://console.cloud.google.com/home/dashboard?project=elevated-module-462113-f0**Support:**- Google Cloud: https://cloud.google.com/support- Community: https://www.googlecloudcommunity.com/---**üöÄ DEPLOY NOW:**```bash./deploy-gcp.sh```Time: 10-15 minutes | Cost: ~$54-69/month | Auto-scaling: Yes---*Quick Deploy Guide**YouAndINotAI Dating Platform v1.0**Google Cloud Platform Deployment*
Collapse file‚ÄéSQUARE-PERMISSION-ISSUE.md‚ÄéCopy file name to clipboard+123Lines changed: 123 additions & 0 deletionsDisplay the source diffDisplay the rich diffOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,123 @@# Square Access Token - Permission Issue## Current ProblemAll Square access tokens are returning **"Access denied" (403)** from the API.This means the tokens either:1. Don't have the required OAuth scopes/permissions2. Are from a different Square application3. Have expired or been revoked4. Are test/sandbox tokens being used with production endpoints## What You Need to Do in Square Dashboard### Step 1: Go to Your Square Application1. Visit: https://developer.squareup.com/apps2. Sign in with your Square account3. You should see your application listed### Step 2: Check Application Permissions1. Click on your application2. In the left sidebar, click **"OAuth"**3. Make sure these permissions are **ENABLED** (checked):   **Required Permissions:**   - ‚úÖ **MERCHANT_PROFILE_READ** - Read merchant profile   - ‚úÖ **ITEMS_READ** - Read items/catalog   - ‚úÖ **ITEMS_WRITE** - Create/update items/catalog   - ‚úÖ **SUBSCRIPTIONS_READ** - Read subscriptions   - ‚úÖ **SUBSCRIPTIONS_WRITE** - Create/manage subscriptions   - ‚úÖ **PAYMENTS_READ** - Read payment information   - ‚úÖ **PAYMENTS_WRITE** - Process payments   - ‚úÖ **CUSTOMERS_READ** - Read customer information   - ‚úÖ **CUSTOMERS_WRITE** - Create/update customers   - ‚úÖ **INVOICES_READ** - Read invoices   - ‚úÖ **INVOICES_WRITE** - Create invoices4. If any are unchecked, **check them** and click **"Save"**### Step 3: Get a NEW Access Token**IMPORTANT:** After changing permissions, you MUST generate a new access token!1. In the left sidebar, click **"Credentials"**2. Scroll to the **"Production"** section (NOT Sandbox)3. Find **"Production Access Token"**4. Click **"Show"** or **"Reveal"**5. Copy the ENTIRE token (should be exactly 64 characters)### Step 4: Verify It's a Production TokenMake sure you're getting the token from:- ‚úÖ **Production** section (for live payments)- ‚ùå NOT **Sandbox** section (for testing only)### Step 5: Provide the New TokenOnce you have the new token from the **Production** section with all permissions enabled:1. Copy it completely2. Provide it to me3. I'll test it and deploy if valid## How to Test the Token YourselfOpen a terminal and run:```bashcurl -X GET 'https://connect.squareup.com/v2/locations' \  -H 'Square-Version: 2024-01-18' \  -H 'Authorization: Bearer YOUR_NEW_TOKEN_HERE'```**Good Response (Token Works):**```json{  "locations": [    {      "id": "LHPBX0P3TBTEC",      "name": "Your Business",      "status": "ACTIVE"    }  ]}```**Bad Response (Token Doesn't Work):**```Access denied```## Current Configuration```SQUARE_ACCESS_TOKEN=EAAAl075KkNm0puso65L3USDTz272NzPwY2KScWWIs8IB1qf8-sFu0q51KSy2zibSQUARE_APP_ID=sq0idp-Carv59GQKuQHoIydJ1WanwSQUARE_LOCATION_ID=LHPBX0P3TBTEC```## Why This MattersWithout a valid access token with proper permissions:- ‚ùå Cannot create subscription plans in Square- ‚ùå Cannot process payments- ‚ùå Cannot manage customer subscriptions- ‚ùå Cannot receive webhook notificationsWith a valid token:- ‚úÖ Automatically create 3 subscription plans ($9.99, $19.99, $29.99)- ‚úÖ Process live payments- ‚úÖ Manage customer subscriptions- ‚úÖ Receive real-time payment notifications## Next Steps1. Go to Square Dashboard2. Enable all required permissions in OAuth section3. Get NEW Production Access Token from Credentials4. Test the token with curl command above5. If it returns locations, provide it to me6. I'll deploy everything automatically
Collapse file‚ÄéSQUARE-TOKEN-GUIDE.md‚ÄéCopy file name to clipboard+104Lines changed: 104 additions & 0 deletionsDisplay the source diffDisplay the rich diffOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,104 @@# How to Get a Valid Square Access Token## ProblemCurrent tokens are returning "Access denied" (403) when accessing Square API.## Solution: Get a Personal Access Token from Square Dashboard### Step-by-Step Instructions:1. **Log into Square Developer Dashboard**   - Go to: https://developer.squareup.com/apps   - Sign in with your Square account2. **Select Your Application**   - Click on your application name   - If you don't have an app, click "+" to create one3. **Navigate to Credentials**   - In the left sidebar, click **"Credentials"**   - You'll see two sections: Sandbox and Production4. **Get Production Personal Access Token**   - Scroll down to **"Production"** section   - Find **"Production Access Token"**   - Click **"Show"** button   - Copy the ENTIRE token (should be ~64 characters starting with "EAAA")5. **Verify Token Permissions**   - Still in Credentials page   - Check that your application has these permissions:     - ‚úÖ Merchant Profile (Read)     - ‚úÖ Items (Read & Write)     - ‚úÖ Subscriptions (Read & Write)     - ‚úÖ Payments (Read & Write)     - ‚úÖ Customers (Read & Write)6. **If Permissions are Missing:**   - Click **"OAuth"** in left sidebar   - Enable all required scopes   - Click **"Save"**   - Go back to **"Credentials"**   - You may need to regenerate the token### Alternative: Check if Token is Sandbox vs Production**Sandbox Token:**- Used for testing only- Works with: `connect.squareupsandbox.com`- Location ID starts with: `L...` (sandbox location)**Production Token:**- Used for real payments- Works with: `connect.squareup.com`- Location ID starts with: `L...` (production location)### Test Your TokenOnce you have the token, test it with:```bash# Production testcurl -X GET 'https://connect.squareup.com/v2/locations' \  -H 'Square-Version: 2024-01-18' \  -H 'Authorization: Bearer YOUR_TOKEN_HERE' \  -H 'Content-Type: application/json'```**Expected Response:**```json{  "locations": [    {      "id": "LHPBX0P3TBTEC",      "name": "Your Business Name",      "address": {...},      "status": "ACTIVE"    }  ]}```**If you get "Access denied":**- Token is invalid, expired, or lacks permissions- Get a new token from Square Dashboard- Verify you're using Production token for production environment### Common Issues:‚ùå **"Access denied"** - Token lacks required permissions or is expired‚ùå **"Unauthorized"** - Token format is wrong or not provided‚ùå **"Not Found"** - Using sandbox token with production endpoint (or vice versa)### Need Help?Square Support: https://squareup.com/help/contact## Once You Have a Valid Token:1. Copy the token2. Provide it to me3. I'll update the .env file4. Run the deployment script5. Create subscription plans automatically
Collapse file‚Äébackend/dating-server-complete.js‚ÄéCopy file name to clipboardExpand all lines: backend/dating-server-complete.js+2Lines changed: 2 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -19,6 +19,7 @@ const SquarePaymentService = require('./services/square-payment');const AIMatchingService = require('./services/ai-matching');const messagingRoutes = require('./routes/messaging');const paymentRoutes = require('./routes/payments');const manusRoutes = require('./routes/manus');const app = express();const server = http.createServer(app);@@ -748,6 +749,7 @@ app.get('/api/matches', authenticateToken, async (req, res) => {// Mount modular routesapp.use('/api/messages', authenticateToken, messagingRoutes(pool, io));app.use('/api/payments', authenticateToken, paymentRoutes(pool, paymentService, requirePremium));app.use('/api/manus', manusRoutes(pool, authenticateToken));// ============================================================================// ERROR HANDLING
Collapse file‚Äébackend/routes/manus.js‚ÄéCopy file name to clipboard+290Lines changed: 290 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,290 @@/** * Manus AI Integration Routes */const express = require('express');const ManusAPIService = require('../services/manus-api');module.exports = (pool, authenticateToken) => {    const router = express.Router();    const manus = new ManusAPIService();    // Generate profile bio    router.post('/profile/bio', authenticateToken, async (req, res) => {        try {            const { userId } = req.body;            const userResult = await pool.query(                'SELECT name, age, occupation FROM user_profiles WHERE user_id = $1',                [userId]            );            const interestsResult = await pool.query(                'SELECT interest FROM user_interests WHERE user_id = $1',                [userId]            );            const userProfile = {                name: userResult.rows[0]?.first_name,                age: userResult.rows[0]?.age,                occupation: userResult.rows[0]?.occupation,                interests: interestsResult.rows.map(r => r.interest)            };            const result = await manus.generateProfileBio(userProfile);            if (result.success) {                res.json({                    success: true,                    bio: result.data.output,                    taskId: result.taskId                });            } else {                res.status(500).json({ error: result.error });            }        } catch (error) {            console.error('Bio generation error:', error);            res.status(500).json({ error: 'Failed to generate bio' });        }    });    // Analyze match compatibility    router.post('/match/analyze', authenticateToken, async (req, res) => {        try {            const { user1Id, user2Id } = req.body;            const user1 = await pool.query(                `SELECT up.first_name as name, EXTRACT(YEAR FROM AGE(up.date_of_birth)) as age,                        array_agg(ui.interest) as interests                 FROM user_profiles up                 LEFT JOIN user_interests ui ON ui.user_id = up.user_id                 WHERE up.user_id = $1                 GROUP BY up.first_name, up.date_of_birth`,                [user1Id]            );            const user2 = await pool.query(                `SELECT up.first_name as name, EXTRACT(YEAR FROM AGE(up.date_of_birth)) as age,                        array_agg(ui.interest) as interests                 FROM user_profiles up                 LEFT JOIN user_interests ui ON ui.user_id = up.user_id                 WHERE up.user_id = $1                 GROUP BY up.first_name, up.date_of_birth`,                [user2Id]            );            const result = await manus.analyzeMatchCompatibility(                user1.rows[0],                user2.rows[0]            );            if (result.success) {                res.json({                    success: true,                    analysis: result.data.output,                    taskId: result.taskId                });            } else {                res.status(500).json({ error: result.error });            }        } catch (error) {            console.error('Match analysis error:', error);            res.status(500).json({ error: 'Failed to analyze match' });        }    });    // Generate icebreakers    router.post('/match/icebreakers', authenticateToken, async (req, res) => {        try {            const { matchId } = req.body;            const matchData = await pool.query(                `SELECT m.user1_id, m.user2_id,                        array_agg(DISTINCT ui1.interest) FILTER (WHERE ui1.interest IS NOT NULL) as user1_interests,                        array_agg(DISTINCT ui2.interest) FILTER (WHERE ui2.interest IS NOT NULL) as user2_interests                 FROM matches m                 LEFT JOIN user_interests ui1 ON ui1.user_id = m.user1_id                 LEFT JOIN user_interests ui2 ON ui2.user_id = m.user2_id                 WHERE m.id = $1                 GROUP BY m.user1_id, m.user2_id`,                [matchId]            );            const match = matchData.rows[0];            const sharedInterests = match.user1_interests?.filter(i =>                match.user2_interests?.includes(i)            ) || [];            const result = await manus.generateIcebreakers({                sharedInterests            });            if (result.success) {                res.json({                    success: true,                    icebreakers: result.data.output,                    taskId: result.taskId                });            } else {                res.status(500).json({ error: result.error });            }        } catch (error) {            console.error('Icebreaker generation error:', error);            res.status(500).json({ error: 'Failed to generate icebreakers' });        }    });    // Moderate content    router.post('/moderate', authenticateToken, async (req, res) => {        try {            const { content, contentType } = req.body;            const result = await manus.moderateContent(content, contentType);            if (result.success) {                res.json({                    success: true,                    moderation: result.data.output,                    safe: result.data.output.is_safe,                    taskId: result.taskId                });            } else {                res.status(500).json({ error: result.error });            }        } catch (error) {            console.error('Moderation error:', error);            res.status(500).json({ error: 'Failed to moderate content' });        }    });    // Generate social media content    router.post('/social/generate', authenticateToken, async (req, res) => {        try {            const { platform, topic } = req.body;            const result = await manus.generateSocialContent(platform, topic);            if (result.success) {                // Store in database for scheduling                await pool.query(                    `INSERT INTO social_posts (platform, content, status, created_by, created_at)                     VALUES ($1, $2, 'draft', $3, NOW())`,                    [platform, result.data.output, req.userId]                );                res.json({                    success: true,                    content: result.data.output,                    taskId: result.taskId                });            } else {                res.status(500).json({ error: result.error });            }        } catch (error) {            console.error('Social content generation error:', error);            res.status(500).json({ error: 'Failed to generate content' });        }    });    // Generate email campaign    router.post('/email/campaign', authenticateToken, async (req, res) => {        try {            const { campaignType, targetAudience } = req.body;            const result = await manus.generateEmailCampaign(campaignType, targetAudience);            if (result.success) {                res.json({                    success: true,                    campaign: result.data.output,                    taskId: result.taskId                });            } else {                res.status(500).json({ error: result.error });            }        } catch (error) {            console.error('Email campaign generation error:', error);            res.status(500).json({ error: 'Failed to generate campaign' });        }    });    // Generate grant content    router.post('/grant/generate', authenticateToken, async (req, res) => {        try {            const { grantName, amount } = req.body;            const result = await manus.generateGrantContent({                name: grantName,                amount: amount            });            if (result.success) {                res.json({                    success: true,                    content: result.data.output,                    taskId: result.taskId                });            } else {                res.status(500).json({ error: result.error });            }        } catch (error) {            console.error('Grant content generation error:', error);            res.status(500).json({ error: 'Failed to generate grant content' });        }    });    // Webhook handler for Manus callbacks    router.post('/webhook', async (req, res) => {        try {            const { event, taskId, status, output } = req.body;            console.log(`Manus webhook: ${event} - Task ${taskId} - Status: ${status}`);            // Store task result in database            await pool.query(                `INSERT INTO ai_tasks (task_id, event_type, status, output, received_at)                 VALUES ($1, $2, $3, $4, NOW())`,                [taskId, event, status, JSON.stringify(output)]            );            // Process based on event type            if (event === 'task.completed') {                // Update related records, send notifications, etc.                console.log(`Task ${taskId} completed successfully`);            } else if (event === 'task.failed') {                console.error(`Task ${taskId} failed:`, output.error);            }            res.json({ received: true });        } catch (error) {            console.error('Webhook processing error:', error);            res.status(500).json({ error: 'Webhook processing failed' });        }    });    // Get task status    router.get('/task/:taskId', authenticateToken, async (req, res) => {        try {            const { taskId } = req.params;            const result = await pool.query(                'SELECT * FROM ai_tasks WHERE task_id = $1',                [taskId]            );            if (result.rows.length > 0) {                res.json({                    success: true,                    task: result.rows[0]                });            } else {                res.status(404).json({ error: 'Task not found' });            }        } catch (error) {            console.error('Task retrieval error:', error);            res.status(500).json({ error: 'Failed to retrieve task' });        }    });    return router;};
Collapse file‚Äébackend/services/manus-api.js‚ÄéCopy file name to clipboard+359Lines changed: 359 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,359 @@/** * Manus API Integration Service * Complete AI agent integration for YouAndINotAI */const axios = require('axios');class ManusAPIService {    constructor() {        this.baseURL = 'https://api.manus.ai/v1';        this.apiKey = process.env.MANUS_API_KEY;        if (!this.apiKey) {            console.warn('‚ö†Ô∏è  MANUS_API_KEY not set - Manus features disabled');        }        this.client = axios.create({            baseURL: this.baseURL,            headers: {                'Authorization': `Bearer ${this.apiKey}`,                'Content-Type': 'application/json'            }        });    }    /**     * Create AI task for various automation needs     */    async createTask(taskConfig) {        try {            const response = await this.client.post('/tasks', taskConfig);            return {                success: true,                taskId: response.data.id,                data: response.data            };        } catch (error) {            console.error('Manus task creation failed:', error.response?.data || error.message);            return {                success: false,                error: error.response?.data?.message || error.message            };        }    }    /**     * Register webhook for task notifications     */    async registerWebhook(webhookUrl, events = ['task.completed', 'task.failed']) {        try {            const response = await this.client.post('/webhooks', {                url: webhookUrl,                events: events            });            return {                success: true,                webhookId: response.data.id,                data: response.data            };        } catch (error) {            console.error('Webhook registration failed:', error.response?.data || error.message);            return {                success: false,                error: error.response?.data?.message || error.message            };        }    }    /**     * Delete webhook     */    async deleteWebhook(webhookId) {        try {            await this.client.delete(`/webhooks/${webhookId}`);            return { success: true };        } catch (error) {            console.error('Webhook deletion failed:', error.response?.data || error.message);            return {                success: false,                error: error.response?.data?.message || error.message            };        }    }    // ========================================    // YOUANDINOTAI-SPECIFIC AI TASKS    // ========================================    /**     * Generate dating profile bio using AI     */    async generateProfileBio(userProfile) {        return await this.createTask({            type: 'text_generation',            prompt: `Generate an engaging dating profile bio for:                Name: ${userProfile.name}                Age: ${userProfile.age}                Interests: ${userProfile.interests?.join(', ') || 'various activities'}                Occupation: ${userProfile.occupation || 'professional'}                Make it authentic, fun, and 50-100 words. Focus on personality and interests.`,            parameters: {                max_tokens: 150,                temperature: 0.8            }        });    }    /**     * Analyze match compatibility with detailed insights     */    async analyzeMatchCompatibility(user1, user2) {        return await this.createTask({            type: 'analysis',            prompt: `Analyze dating compatibility between:                Person 1: ${user1.name}, ${user1.age}, interests: ${user1.interests?.join(', ')}                Person 2: ${user2.name}, ${user2.age}, interests: ${user2.interests?.join(', ')}                Provide:                1. Compatibility score (0-100)                2. 3 key compatibility factors                3. Potential conversation starters                4. Relationship advice`,            parameters: {                format: 'json'            }        });    }    /**     * Generate icebreaker messages     */    async generateIcebreakers(matchContext) {        return await this.createTask({            type: 'text_generation',            prompt: `Generate 5 creative icebreaker messages for a dating match:                Context: ${matchContext.sharedInterests?.join(', ') || 'getting to know each other'}                Make them:                - Short (under 50 characters)                - Fun and engaging                - Personalized to their interests                - Not generic`,            parameters: {                count: 5,                max_length: 50            }        });    }    /**     * Content moderation for messages and profiles     */    async moderateContent(content, contentType = 'message') {        return await this.createTask({            type: 'moderation',            content: content,            parameters: {                content_type: contentType,                strict_mode: true,                categories: [                    'harassment',                    'hate_speech',                    'explicit_content',                    'spam',                    'scam'                ]            }        });    }    /**     * Generate social media content for marketing     */    async generateSocialContent(platform, topic) {        const platformSpecs = {            instagram: { length: 150, tone: 'casual', hashtags: 5 },            twitter: { length: 280, tone: 'concise', hashtags: 3 },            facebook: { length: 300, tone: 'friendly', hashtags: 2 },            tiktok: { length: 100, tone: 'energetic', hashtags: 4 }        };        const spec = platformSpecs[platform] || platformSpecs.instagram;        return await this.createTask({            type: 'social_media',            prompt: `Create ${platform} post about: ${topic}                Requirements:                - ${spec.tone} tone                - Max ${spec.length} characters                - Include ${spec.hashtags} relevant hashtags                - Engaging call-to-action                - Emoji usage                Topic focus: Human-verified dating, anti-AI authenticity`,            parameters: spec        });    }    /**     * Customer support ticket analysis     */    async analyzeSupport Ticket(ticketData) {        return await this.createTask({            type: 'customer_support',            prompt: `Analyze support ticket:                Subject: ${ticketData.subject}                Message: ${ticketData.message}                User: ${ticketData.userEmail}                Provide:                1. Issue category                2. Priority (low/medium/high)                3. Suggested resolution                4. Response template`,            parameters: {                format: 'json'            }        });    }    /**     * Grant application content generation     */    async generateGrantContent(grantInfo) {        return await this.createTask({            type: 'document_generation',            prompt: `Generate grant application content for:                Grant: ${grantInfo.name}                Amount: ${grantInfo.amount}                Focus: Anti-monopoly, privacy-focused dating platform                Generate:                1. Executive summary (200 words)                2. Problem statement (300 words)                3. Solution approach (400 words)                4. Budget justification (200 words)`,            parameters: {                sections: ['executive_summary', 'problem', 'solution', 'budget'],                formal_tone: true            }        });    }    /**     * Email campaign generation     */    async generateEmailCampaign(campaignType, targetAudience) {        return await this.createTask({            type: 'email_marketing',            prompt: `Create email campaign:                Type: ${campaignType}                Audience: ${targetAudience}                Product: YouAndINotAI dating platform                Include:                - Subject line (compelling, 50 chars)                - Preview text                - Email body (300 words)                - Call-to-action                - PS line`,            parameters: {                personalization: true,                include_visuals: true            }        });    }    /**     * DAO proposal content generation     */    async generateDAOProposal(proposalIdea) {        return await this.createTask({            type: 'governance',            prompt: `Create DAO governance proposal:                Idea: ${proposalIdea.title}                Description: ${proposalIdea.description}                Generate:                1. Formal proposal title                2. Executive summary                3. Implementation plan                4. Budget breakdown                5. Success metrics                6. Voting options`,            parameters: {                format: 'governance_standard',                include_risks: true            }        });    }    /**     * Product description for merch store     */    async generateProductDescription(product) {        return await this.createTask({            type: 'e-commerce',            prompt: `Create product description for anti-AI merchandise:                Product: ${product.name}                Type: ${product.type}                Message: "100% Human", anti-AI movement                Generate:                - Catchy title                - Engaging description (100 words)                - Key features (5 bullets)                - Why buy this                - SEO keywords`,            parameters: {                seo_optimized: true,                persuasive: true            }        });    }    /**     * Analytics insights generation     */    async generateAnalyticsInsights(metricsData) {        return await this.createTask({            type: 'analytics',            prompt: `Analyze platform metrics and provide insights:                Users: ${metricsData.totalUsers}                Active: ${metricsData.activeUsers}                Matches: ${metricsData.totalMatches}                Revenue: $${metricsData.revenue}                Provide:                1. Key trends                2. Growth opportunities                3. Concerns/risks                4. Actionable recommendations`,            parameters: {                format: 'executive_report',                include_charts: true            }        });    }    /**     * Batch processing for multiple tasks     */    async processBatch(tasks) {        const promises = tasks.map(task => this.createTask(task));        const results = await Promise.allSettled(promises);        return results.map((result, index) => ({            taskIndex: index,            success: result.status === 'fulfilled',            data: result.status === 'fulfilled' ? result.value : null,            error: result.status === 'rejected' ? result.reason : null        }));    }}module.exports = ManusAPIService;
Collapse file‚Äédatabase/schema.sql‚ÄéCopy file name to clipboardExpand all lines: database/schema.sql+36Lines changed: 36 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -419,6 +419,42 @@ LEFT JOIN subscription_plans sp ON sp.id = us.plan_idWHERE u.status = 'active'GROUP BY u.id, up.first_name, up.display_name, us.status, sp.display_name;-- ============================================================================-- MANUS AI INTEGRATION TABLES-- ============================================================================-- AI tasks trackingCREATE TABLE ai_tasks (    id SERIAL PRIMARY KEY,    task_id VARCHAR(255) UNIQUE NOT NULL,    event_type VARCHAR(100) NOT NULL,    status VARCHAR(50) NOT NULL,    output JSONB,    received_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP);CREATE INDEX idx_ai_tasks_task_id ON ai_tasks(task_id);CREATE INDEX idx_ai_tasks_status ON ai_tasks(status);CREATE INDEX idx_ai_tasks_received_at ON ai_tasks(received_at);-- Social media posts managementCREATE TABLE social_posts (    id SERIAL PRIMARY KEY,    platform VARCHAR(50) NOT NULL,    content TEXT NOT NULL,    status VARCHAR(50) DEFAULT 'draft',    scheduled_for TIMESTAMP,    posted_at TIMESTAMP,    created_by INTEGER REFERENCES users(id) ON DELETE SET NULL,    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP);CREATE INDEX idx_social_posts_platform ON social_posts(platform);CREATE INDEX idx_social_posts_status ON social_posts(status);CREATE INDEX idx_social_posts_scheduled_for ON social_posts(scheduled_for);-- ============================================================================-- GRANTS-- ============================================================================
Collapse file‚Äédeploy-aws.sh‚ÄéCopy file name to clipboard+359Lines changed: 359 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,359 @@#!/bin/bash# YouAndINotAI - AWS Deployment Script# Deploys complete dating platform to AWSset -eecho "üöÄ YouAndINotAI AWS Deployment"# ConfigurationAWS_REGION="us-east-1"APP_NAME="youandinotai"ECR_REPO="${APP_NAME}-backend"ECS_CLUSTER="${APP_NAME}-cluster"ECS_SERVICE="${APP_NAME}-service"RDS_INSTANCE="${APP_NAME}-db"ELASTICACHE_CLUSTER="${APP_NAME}-redis"# ColorsGREEN='\033[0;32m'YELLOW='\033[1;33m'NC='\033[0m'# Check AWS CLIif ! command -v aws &> /dev/null; then    echo "‚ùå AWS CLI not installed"    echo "Install: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html"    exit 1fi# Check Dockerif ! command -v docker &> /dev/null; then    echo "‚ùå Docker not installed"    exit 1fiecho -e "${YELLOW}Step 1: Configure AWS${NC}"aws configure listread -p "AWS configuration correct? (y/n) " -n 1 -rechoif [[ ! $REPLY =~ ^[Yy]$ ]]; then    aws configurefiecho -e "${YELLOW}Step 2: Create VPC and Security Groups${NC}"VPC_ID=$(aws ec2 create-vpc \    --cidr-block 10.0.0.0/16 \    --query 'Vpc.VpcId' \    --output text \    --region $AWS_REGION)echo "VPC Created: $VPC_ID"aws ec2 create-tags \    --resources $VPC_ID \    --tags Key=Name,Value=${APP_NAME}-vpc \    --region $AWS_REGION# Enable DNSaws ec2 modify-vpc-attribute \    --vpc-id $VPC_ID \    --enable-dns-hostnames \    --region $AWS_REGION# Create Internet GatewayIGW_ID=$(aws ec2 create-internet-gateway \    --query 'InternetGateway.InternetGatewayId' \    --output text \    --region $AWS_REGION)aws ec2 attach-internet-gateway \    --vpc-id $VPC_ID \    --internet-gateway-id $IGW_ID \    --region $AWS_REGION# Create Subnets (2 public, 2 private)SUBNET_PUBLIC_1=$(aws ec2 create-subnet \    --vpc-id $VPC_ID \    --cidr-block 10.0.1.0/24 \    --availability-zone ${AWS_REGION}a \    --query 'Subnet.SubnetId' \    --output text \    --region $AWS_REGION)SUBNET_PUBLIC_2=$(aws ec2 create-subnet \    --vpc-id $VPC_ID \    --cidr-block 10.0.2.0/24 \    --availability-zone ${AWS_REGION}b \    --query 'Subnet.SubnetId' \    --output text \    --region $AWS_REGION)SUBNET_PRIVATE_1=$(aws ec2 create-subnet \    --vpc-id $VPC_ID \    --cidr-block 10.0.3.0/24 \    --availability-zone ${AWS_REGION}a \    --query 'Subnet.SubnetId' \    --output text \    --region $AWS_REGION)SUBNET_PRIVATE_2=$(aws ec2 create-subnet \    --vpc-id $VPC_ID \    --cidr-block 10.0.4.0/24 \    --availability-zone ${AWS_REGION}b \    --query 'Subnet.SubnetId' \    --output text \    --region $AWS_REGION)echo "Subnets Created"# Create Security GroupSG_ID=$(aws ec2 create-security-group \    --group-name ${APP_NAME}-sg \    --description "YouAndINotAI Security Group" \    --vpc-id $VPC_ID \    --query 'GroupId' \    --output text \    --region $AWS_REGION)# Allow HTTP/HTTPSaws ec2 authorize-security-group-ingress \    --group-id $SG_ID \    --protocol tcp \    --port 80 \    --cidr 0.0.0.0/0 \    --region $AWS_REGIONaws ec2 authorize-security-group-ingress \    --group-id $SG_ID \    --protocol tcp \    --port 443 \    --cidr 0.0.0.0/0 \    --region $AWS_REGIONaws ec2 authorize-security-group-ingress \    --group-id $SG_ID \    --protocol tcp \    --port 3000 \    --cidr 0.0.0.0/0 \    --region $AWS_REGIONecho -e "${GREEN}‚úÖ VPC and Security Groups Created${NC}"echo -e "${YELLOW}Step 3: Create RDS PostgreSQL Database${NC}"aws rds create-db-instance \    --db-instance-identifier $RDS_INSTANCE \    --db-instance-class db.t3.micro \    --engine postgres \    --engine-version 16.1 \    --master-username postgres \    --master-user-password "$(openssl rand -base64 32)" \    --allocated-storage 20 \    --vpc-security-group-ids $SG_ID \    --db-subnet-group-name default \    --publicly-accessible \    --region $AWS_REGION || echo "RDS may already exist"echo "Waiting for RDS..."aws rds wait db-instance-available \    --db-instance-identifier $RDS_INSTANCE \    --region $AWS_REGIONRDS_ENDPOINT=$(aws rds describe-db-instances \    --db-instance-identifier $RDS_INSTANCE \    --query 'DBInstances[0].Endpoint.Address' \    --output text \    --region $AWS_REGION)echo -e "${GREEN}‚úÖ RDS Created: $RDS_ENDPOINT${NC}"echo -e "${YELLOW}Step 4: Create ElastiCache Redis${NC}"aws elasticache create-cache-cluster \    --cache-cluster-id $ELASTICACHE_CLUSTER \    --cache-node-type cache.t3.micro \    --engine redis \    --num-cache-nodes 1 \    --security-group-ids $SG_ID \    --region $AWS_REGION || echo "ElastiCache may already exist"echo "Waiting for ElastiCache..."sleep 30REDIS_ENDPOINT=$(aws elasticache describe-cache-clusters \    --cache-cluster-id $ELASTICACHE_CLUSTER \    --show-cache-node-info \    --query 'CacheClusters[0].CacheNodes[0].Endpoint.Address' \    --output text \    --region $AWS_REGION)echo -e "${GREEN}‚úÖ ElastiCache Created: $REDIS_ENDPOINT${NC}"echo -e "${YELLOW}Step 5: Create ECR Repository${NC}"aws ecr create-repository \    --repository-name $ECR_REPO \    --region $AWS_REGION || echo "ECR repo may already exist"ECR_URI=$(aws ecr describe-repositories \    --repository-names $ECR_REPO \    --query 'repositories[0].repositoryUri' \    --output text \    --region $AWS_REGION)echo -e "${GREEN}‚úÖ ECR Repository: $ECR_URI${NC}"echo -e "${YELLOW}Step 6: Build and Push Docker Image${NC}"aws ecr get-login-password --region $AWS_REGION | \    docker login --username AWS --password-stdin $ECR_URIdocker build -t $APP_NAME ./backenddocker tag $APP_NAME:latest $ECR_URI:latestdocker push $ECR_URI:latestecho -e "${GREEN}‚úÖ Docker Image Pushed${NC}"echo -e "${YELLOW}Step 7: Create ECS Cluster${NC}"aws ecs create-cluster \    --cluster-name $ECS_CLUSTER \    --region $AWS_REGION || echo "ECS cluster may already exist"echo -e "${GREEN}‚úÖ ECS Cluster Created${NC}"echo -e "${YELLOW}Step 8: Create Task Definition${NC}"cat > task-definition.json <<EOF{  "family": "${APP_NAME}-task",  "networkMode": "awsvpc",  "requiresCompatibilities": ["FARGATE"],  "cpu": "256",  "memory": "512",  "containerDefinitions": [    {      "name": "${APP_NAME}-container",      "image": "${ECR_URI}:latest",      "portMappings": [        {          "containerPort": 3000,          "protocol": "tcp"        }      ],      "environment": [        {          "name": "NODE_ENV",          "value": "production"        },        {          "name": "DATABASE_URL",          "value": "postgresql://postgres:CHANGE_ME@${RDS_ENDPOINT}:5432/youandinotai_prod"        },        {          "name": "REDIS_URL",          "value": "redis://${REDIS_ENDPOINT}:6379"        },        {          "name": "SQUARE_ACCESS_TOKEN",          "value": "EAAAlzPv9mOdHtwWwGJsCHXaG_5Ektf_rIvg4H6tiKRzTQSW9UHiVHUBDuHTOQYc"        },        {          "name": "GEMINI_API_KEY",          "value": "AIzaSyBuaA6sdJ2kvIeXiL1jY4Qm7StXAUwFWG4"        },        {          "name": "AZURE_COGNITIVE_KEY",          "value": "CScbecGnFd4YLCWpvmdAZ5yxkV6U2O5L02xPcp6f2bEYIMiJesdtJQQJ99BHACYeBjFXJ3w3AAABACOGHJUX"        },        {          "name": "MANUS_API_KEY",          "value": "YOUR_MANUS_API_KEY_HERE"        }      ],      "logConfiguration": {        "logDriver": "awslogs",        "options": {          "awslogs-group": "/ecs/${APP_NAME}",          "awslogs-region": "${AWS_REGION}",          "awslogs-stream-prefix": "ecs"        }      }    }  ]}EOFaws ecs register-task-definition \    --cli-input-json file://task-definition.json \    --region $AWS_REGIONecho -e "${GREEN}‚úÖ Task Definition Created${NC}"echo -e "${YELLOW}Step 9: Create Application Load Balancer${NC}"ALB_ARN=$(aws elbv2 create-load-balancer \    --name ${APP_NAME}-alb \    --subnets $SUBNET_PUBLIC_1 $SUBNET_PUBLIC_2 \    --security-groups $SG_ID \    --query 'LoadBalancers[0].LoadBalancerArn' \    --output text \    --region $AWS_REGION)ALB_DNS=$(aws elbv2 describe-load-balancers \    --load-balancer-arns $ALB_ARN \    --query 'LoadBalancers[0].DNSName' \    --output text \    --region $AWS_REGION)# Create Target GroupTG_ARN=$(aws elbv2 create-target-group \    --name ${APP_NAME}-tg \    --protocol HTTP \    --port 3000 \    --vpc-id $VPC_ID \    --target-type ip \    --health-check-path /health \    --query 'TargetGroups[0].TargetGroupArn' \    --output text \    --region $AWS_REGION)# Create Listeneraws elbv2 create-listener \    --load-balancer-arn $ALB_ARN \    --protocol HTTP \    --port 80 \    --default-actions Type=forward,TargetGroupArn=$TG_ARN \    --region $AWS_REGIONecho -e "${GREEN}‚úÖ Load Balancer Created: $ALB_DNS${NC}"echo -e "${YELLOW}Step 10: Create ECS Service${NC}"aws ecs create-service \    --cluster $ECS_CLUSTER \    --service-name $ECS_SERVICE \    --task-definition ${APP_NAME}-task \    --desired-count 2 \    --launch-type FARGATE \    --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_PRIVATE_1,$SUBNET_PRIVATE_2],securityGroups=[$SG_ID],assignPublicIp=ENABLED}" \    --load-balancers "targetGroupArn=$TG_ARN,containerName=${APP_NAME}-container,containerPort=3000" \    --region $AWS_REGIONecho -e "${GREEN}‚úÖ ECS Service Created${NC}"echo ""echo "============================================"echo "üéâ AWS DEPLOYMENT COMPLETE!"echo "============================================"echo ""echo "üìä Resources:"echo "   VPC: $VPC_ID"echo "   RDS: $RDS_ENDPOINT"echo "   Redis: $REDIS_ENDPOINT"echo "   ECR: $ECR_URI"echo "   ECS Cluster: $ECS_CLUSTER"echo ""echo "üåê Your app is live at:"echo "   http://$ALB_DNS"echo ""echo "‚è∞ Wait 2-3 minutes for services to start"echo ""echo "‚úÖ Next Steps:"echo "   1. Point youandinotai.com DNS to: $ALB_DNS"echo "   2. Add SSL certificate via AWS Certificate Manager"echo "   3. Update RDS password in Secrets Manager"echo "   4. Monitor: aws ecs describe-services --cluster $ECS_CLUSTER"echo ""
Collapse file‚Äédeploy-gcp.sh‚ÄéCopy file name to clipboard+286Lines changed: 286 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,286 @@#!/bin/bashset -eecho "üöÄ YouAndINotAI - Google Cloud Platform Deployment"echo "=================================================="# ConfigurationPROJECT_ID="elevated-module-462113-f0"REGION="us-central1"APP_NAME="youandinotai"SERVICE_NAME="${APP_NAME}-backend"DB_INSTANCE="${APP_NAME}-db"REDIS_INSTANCE="${APP_NAME}-redis"ARTIFACT_REPO="${APP_NAME}-repo"echo ""echo "üìã Configuration:"echo "   Project: $PROJECT_ID"echo "   Region: $REGION"echo "   Service: $SERVICE_NAME"echo ""# Step 1: Set projectecho "üîß Step 1: Setting GCP project..."gcloud config set project $PROJECT_ID# Step 2: Enable required APIsecho "üîß Step 2: Enabling required GCP APIs..."gcloud services enable \    compute.googleapis.com \    sqladmin.googleapis.com \    redis.googleapis.com \    artifactregistry.googleapis.com \    run.googleapis.com \    cloudresourcemanager.googleapis.com \    vpcaccess.googleapis.com \    servicenetworking.googleapis.com \    secretmanager.googleapis.comecho "‚úÖ APIs enabled"# Step 3: Create Artifact Registry repositoryecho "üîß Step 3: Creating Artifact Registry repository..."if ! gcloud artifacts repositories describe $ARTIFACT_REPO --location=$REGION &>/dev/null; then    gcloud artifacts repositories create $ARTIFACT_REPO \        --repository-format=docker \        --location=$REGION \        --description="Docker repository for YouAndINotAI"    echo "‚úÖ Artifact Registry created"else    echo "‚úÖ Artifact Registry already exists"fi# Step 4: Build and push Docker imageecho "üîß Step 4: Building and pushing Docker image..."IMAGE_URI="${REGION}-docker.pkg.dev/${PROJECT_ID}/${ARTIFACT_REPO}/${SERVICE_NAME}:latest"# Configure Docker to use gcloud credentialsgcloud auth configure-docker ${REGION}-docker.pkg.dev# Build imagedocker build -t $IMAGE_URI -f Dockerfile.gcp .# Push imagedocker push $IMAGE_URIecho "‚úÖ Image pushed: $IMAGE_URI"# Step 5: Create Cloud SQL PostgreSQL instanceecho "üîß Step 5: Creating Cloud SQL PostgreSQL instance..."if ! gcloud sql instances describe $DB_INSTANCE &>/dev/null; then    gcloud sql instances create $DB_INSTANCE \        --database-version=POSTGRES_16 \        --tier=db-f1-micro \        --region=$REGION \        --network=default \        --database-flags=max_connections=100 \        --backup \        --backup-start-time=03:00 \        --retained-backups-count=7 \        --maintenance-window-day=SUN \        --maintenance-window-hour=4    echo "‚úÖ Cloud SQL instance created"    # Set root password    echo "üîß Setting database password..."    gcloud sql users set-password postgres \        --instance=$DB_INSTANCE \        --password=$(openssl rand -base64 32)    # Create database    echo "üîß Creating database..."    gcloud sql databases create youandinotai_prod \        --instance=$DB_INSTANCE    # Create application user    DB_PASSWORD=$(openssl rand -base64 32)    gcloud sql users create youandinotai_user \        --instance=$DB_INSTANCE \        --password=$DB_PASSWORD    echo "‚úÖ Database created: youandinotai_prod"    echo "‚úÖ User created: youandinotai_user"else    echo "‚úÖ Cloud SQL instance already exists"    DB_PASSWORD="YOUR_EXISTING_PASSWORD"fi# Step 6: Create Memorystore Redis instanceecho "üîß Step 6: Creating Memorystore Redis instance..."if ! gcloud redis instances describe $REDIS_INSTANCE --region=$REGION &>/dev/null; then    gcloud redis instances create $REDIS_INSTANCE \        --size=1 \        --region=$REGION \        --redis-version=redis_7_0 \        --tier=basic    echo "‚úÖ Redis instance created"else    echo "‚úÖ Redis instance already exists"fi# Step 7: Get connection detailsecho "üîß Step 7: Getting connection details..."# Get Cloud SQL connection nameSQL_CONNECTION=$(gcloud sql instances describe $DB_INSTANCE \    --format='get(connectionName)')# Get Redis hostREDIS_HOST=$(gcloud redis instances describe $REDIS_INSTANCE \    --region=$REGION \    --format='get(host)')REDIS_PORT=$(gcloud redis instances describe $REDIS_INSTANCE \    --region=$REGION \    --format='get(port)')echo "‚úÖ Cloud SQL Connection: $SQL_CONNECTION"echo "‚úÖ Redis Host: $REDIS_HOST:$REDIS_PORT"# Step 8: Create VPC Connector for Cloud Runecho "üîß Step 8: Creating VPC Access Connector..."VPC_CONNECTOR="${APP_NAME}-vpc-connector"if ! gcloud compute networks vpc-access connectors describe $VPC_CONNECTOR \    --region=$REGION &>/dev/null; then    gcloud compute networks vpc-access connectors create $VPC_CONNECTOR \        --region=$REGION \        --network=default \        --range=10.8.0.0/28 \        --min-instances=2 \        --max-instances=3 \        --machine-type=f1-micro    echo "‚úÖ VPC Connector created"else    echo "‚úÖ VPC Connector already exists"fi# Step 9: Create secrets in Secret Managerecho "üîß Step 9: Storing secrets in Secret Manager..."# Database URL secretif ! gcloud secrets describe db-password &>/dev/null; then    echo -n "$DB_PASSWORD" | gcloud secrets create db-password \        --replication-policy="automatic" \        --data-file=-fi# Square Access Tokenif ! gcloud secrets describe square-token &>/dev/null; then    echo -n "EAAAlzPv9mOdHtwWwGJsCHXaG_5Ektf_rIvg4H6tiKRzTQSW9UHiVHUBDuHTOQYc" | \        gcloud secrets create square-token \        --replication-policy="automatic" \        --data-file=-fi# Gemini API Keyif ! gcloud secrets describe gemini-api-key &>/dev/null; then    echo -n "AIzaSyBuaA6sdJ2kvIeXiL1jY4Qm7StXAUwFWG4" | \        gcloud secrets create gemini-api-key \        --replication-policy="automatic" \        --data-file=-fi# Azure Cognitive Keyif ! gcloud secrets describe azure-cognitive-key &>/dev/null; then    echo -n "CScbecGnFd4YLCWpvmdAZ5yxkV6U2O5L02xPcp6f2bEYIMiJesdtJQQJ99BHACYeBjFXJ3w3AAABACOGHJUX" | \        gcloud secrets create azure-cognitive-key \        --replication-policy="automatic" \        --data-file=-fi# JWT Secretif ! gcloud secrets describe jwt-secret &>/dev/null; then    openssl rand -base64 64 | gcloud secrets create jwt-secret \        --replication-policy="automatic" \        --data-file=-fi# JWT Refresh Secretif ! gcloud secrets describe jwt-refresh-secret &>/dev/null; then    openssl rand -base64 64 | gcloud secrets create jwt-refresh-secret \        --replication-policy="automatic" \        --data-file=-fiecho "‚úÖ Secrets stored in Secret Manager"# Step 10: Deploy to Cloud Runecho "üîß Step 10: Deploying to Cloud Run..."gcloud run deploy $SERVICE_NAME \    --image=$IMAGE_URI \    --platform=managed \    --region=$REGION \    --allow-unauthenticated \    --min-instances=1 \    --max-instances=10 \    --memory=512Mi \    --cpu=1 \    --timeout=300 \    --concurrency=80 \    --port=3000 \    --vpc-connector=$VPC_CONNECTOR \    --add-cloudsql-instances=$SQL_CONNECTION \    --set-env-vars="NODE_ENV=production" \    --set-env-vars="PORT=3000" \    --set-env-vars="SQUARE_APP_ID=sq0idp-Carv59GQKuQHoIydJ1Wanw" \    --set-env-vars="SQUARE_LOCATION_ID=LHPBX0P3TBTEC" \    --set-env-vars="REDIS_HOST=$REDIS_HOST" \    --set-env-vars="REDIS_PORT=$REDIS_PORT" \    --set-env-vars="DATABASE_HOST=/cloudsql/$SQL_CONNECTION" \    --set-env-vars="DATABASE_NAME=youandinotai_prod" \    --set-env-vars="DATABASE_USER=youandinotai_user" \    --set-env-vars="MANUS_API_KEY=YOUR_MANUS_API_KEY_HERE" \    --set-secrets="DATABASE_PASSWORD=db-password:latest" \    --set-secrets="SQUARE_ACCESS_TOKEN=square-token:latest" \    --set-secrets="GEMINI_API_KEY=gemini-api-key:latest" \    --set-secrets="AZURE_COGNITIVE_KEY=azure-cognitive-key:latest" \    --set-secrets="JWT_SECRET=jwt-secret:latest" \    --set-secrets="JWT_REFRESH_SECRET=jwt-refresh-secret:latest"echo "‚úÖ Cloud Run service deployed"# Step 11: Get service URLSERVICE_URL=$(gcloud run services describe $SERVICE_NAME \    --region=$REGION \    --format='get(status.url)')echo ""echo "üéâ DEPLOYMENT COMPLETE!"echo "============================================"echo ""echo "üìä Resources Created:"echo "   Project: $PROJECT_ID"echo "   Region: $REGION"echo "   Cloud SQL: $DB_INSTANCE"echo "   Redis: $REDIS_INSTANCE"echo "   Cloud Run: $SERVICE_NAME"echo "   Artifact Registry: $ARTIFACT_REPO"echo ""echo "üåê Your app is live at:"echo "   $SERVICE_URL"echo ""echo "üîó Cloud SQL Connection:"echo "   $SQL_CONNECTION"echo ""echo "üìã Next Steps:"echo "   1. Test health endpoint: curl $SERVICE_URL/health"echo "   2. Initialize database: gcloud sql connect $DB_INSTANCE --user=youandinotai_user"echo "   3. Add Manus API key: Update secret 'manus-api-key' in Secret Manager"echo "   4. Configure custom domain in Cloud Run console"echo "   5. Set up Cloud CDN for static assets"echo ""echo "üí∞ Estimated Monthly Cost: ~\$45-60"echo "   - Cloud SQL (db-f1-micro): ~\$7"echo "   - Memorystore Redis (1GB): ~\$25"echo "   - Cloud Run (1-10 instances): ~\$10-20"echo "   - Networking: ~\$3-8"echo ""echo "üìñ View logs: gcloud run services logs read $SERVICE_NAME --region=$REGION"echo "üìä Console: https://console.cloud.google.com/run?project=$PROJECT_ID"echo ""
Collapse file‚Äépush-to-youandinotai.sh‚ÄéCopy file name to clipboard+67Lines changed: 67 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,67 @@#!/bin/bash# Push YouAndINotAI Dating Platform to new repository# Repository: https://github.com/youandinotai/youandinotai.gitecho "============================================================"echo "  Push to youandinotai/youandinotai Repository"echo "============================================================"echo ""# Check if remote existsif git remote | grep -q "youandinotai"; then    echo "‚úÖ Remote 'youandinotai' already configured"else    echo "üìù Adding remote 'youandinotai'..."    git remote add youandinotai https://github.com/youandinotai/youandinotai.gitfiecho ""echo "üì§ Pushing current branch to main branch of new repository..."echo ""# Get current branch nameCURRENT_BRANCH=$(git branch --show-current)echo "Current branch: $CURRENT_BRANCH"# Push to new remoteecho ""echo "Executing: git push youandinotai $CURRENT_BRANCH:main"echo ""echo "‚ö†Ô∏è  You may be prompted for GitHub credentials:"echo "   - Username: your GitHub username"echo "   - Password: use a Personal Access Token (not your password)"echo ""echo "To create a Personal Access Token:"echo "1. Go to: https://github.com/settings/tokens"echo "2. Click 'Generate new token' ‚Üí 'Generate new token (classic)'"echo "3. Select scopes: repo (full control of private repositories)"echo "4. Click 'Generate token'"echo "5. Copy the token and use it as your password"echo ""git push youandinotai "$CURRENT_BRANCH:main"if [ $? -eq 0 ]; then    echo ""    echo "============================================================"    echo "‚úÖ Successfully pushed to https://github.com/youandinotai/youandinotai.git"    echo "============================================================"    echo ""    echo "üåê View your repository:"    echo "   https://github.com/youandinotai/youandinotai"    echo ""else    echo ""    echo "============================================================"    echo "‚ùå Push failed"    echo "============================================================"    echo ""    echo "Troubleshooting:"    echo "1. Make sure you have access to the repository"    echo "2. Generate a Personal Access Token at: https://github.com/settings/tokens"    echo "3. Use the token as your password when prompted"    echo ""    echo "Alternative: Push manually"    echo "   git push youandinotai $CURRENT_BRANCH:main"    echo ""fi
Collapse file‚Äéverify-gcp-setup.sh‚ÄéCopy file name to clipboard+219Lines changed: 219 additions & 0 deletionsOriginal file line numberOriginal file lineDiff line numberDiff line change@@ -0,0 +1,219 @@#!/bin/bash# GCP Setup Verification Script for YouAndINotAI# Run this in Google Cloud Shell to verify everything is readyset -eecho "=========================================="echo "Google Cloud Platform Setup Verification"echo "YouAndINotAI Dating Platform"echo "=========================================="echo ""# Colors for outputRED='\033[0;31m'GREEN='\033[0;32m'YELLOW='\033[1;33m'NC='\033[0m' # No Color# Check functionscheck_pass() {    echo -e "${GREEN}‚úì${NC} $1"}check_fail() {    echo -e "${RED}‚úó${NC} $1"}check_warn() {    echo -e "${YELLOW}‚ö†${NC} $1"}# Get current projectCURRENT_PROJECT=$(gcloud config get-value project 2>/dev/null)echo "1. Project Configuration"echo "----------------------------------------"if [ "$CURRENT_PROJECT" = "elevated-module-462113-f0" ]; then    check_pass "Project: $CURRENT_PROJECT"else    check_warn "Current project: $CURRENT_PROJECT"    check_warn "Expected: elevated-module-462113-f0"    echo "   To fix: gcloud config set project elevated-module-462113-f0"fiecho ""echo "2. Authentication"echo "----------------------------------------"ACCOUNT=$(gcloud config get-value account 2>/dev/null)if [ -n "$ACCOUNT" ]; then    check_pass "Authenticated as: $ACCOUNT"else    check_fail "Not authenticated"    echo "   To fix: gcloud auth login"fiecho ""echo "3. Billing Status"echo "----------------------------------------"BILLING_ENABLED=$(gcloud beta billing projects describe $CURRENT_PROJECT --format="value(billingEnabled)" 2>/dev/null || echo "false")if [ "$BILLING_ENABLED" = "True" ]; then    check_pass "Billing is enabled"    BILLING_ACCOUNT=$(gcloud beta billing projects describe $CURRENT_PROJECT --format="value(billingAccountName)" 2>/dev/null)    echo "   Account: $BILLING_ACCOUNT"else    check_fail "Billing is NOT enabled"    echo "   To fix: https://console.cloud.google.com/billing?project=$CURRENT_PROJECT"fiecho ""echo "4. Required APIs"echo "----------------------------------------"REQUIRED_APIS=(    "compute.googleapis.com"    "sqladmin.googleapis.com"    "redis.googleapis.com"    "artifactregistry.googleapis.com"    "run.googleapis.com"    "vpcaccess.googleapis.com"    "secretmanager.googleapis.com")MISSING_APIS=()for API in "${REQUIRED_APIS[@]}"; do    if gcloud services list --enabled --filter="name:$API" --format="value(name)" 2>/dev/null | grep -q "$API"; then        check_pass "$API"    else        check_fail "$API (not enabled)"        MISSING_APIS+=("$API")    fidoneif [ ${#MISSING_APIS[@]} -gt 0 ]; then    echo ""    echo "   To enable missing APIs, run:"    echo "   gcloud services enable ${MISSING_APIS[*]}"fiecho ""echo "5. Existing Resources"echo "----------------------------------------"# Check Cloud SQLSQL_INSTANCES=$(gcloud sql instances list --format="value(name)" 2>/dev/null | wc -l)if [ $SQL_INSTANCES -gt 0 ]; then    check_warn "Found $SQL_INSTANCES Cloud SQL instance(s):"    gcloud sql instances list --format="table(name,region,databaseVersion,state)" 2>/dev/null | tail -n +2else    check_pass "No existing Cloud SQL instances (will be created)"fiecho ""# Check MemorystoreREDIS_INSTANCES=$(gcloud redis instances list --region=us-central1 --format="value(name)" 2>/dev/null | wc -l)if [ $REDIS_INSTANCES -gt 0 ]; then    check_warn "Found $REDIS_INSTANCES Memorystore Redis instance(s):"    gcloud redis instances list --region=us-central1 --format="table(name,region,tier,memorySizeGb,state)" 2>/dev/null | tail -n +2else    check_pass "No existing Redis instances (will be created)"fiecho ""# Check Cloud RunRUN_SERVICES=$(gcloud run services list --platform=managed --region=us-central1 --format="value(name)" 2>/dev/null | wc -l)if [ $RUN_SERVICES -gt 0 ]; then    check_warn "Found $RUN_SERVICES Cloud Run service(s):"    gcloud run services list --platform=managed --region=us-central1 --format="table(SERVICE,REGION,URL,LAST_DEPLOYED)" 2>/dev/null | tail -n +2else    check_pass "No existing Cloud Run services (will be created)"fiecho ""# Check Artifact RegistryREPOS=$(gcloud artifacts repositories list --location=us-central1 --format="value(name)" 2>/dev/null | wc -l)if [ $REPOS -gt 0 ]; then    check_warn "Found $REPOS Artifact Registry repository(s):"    gcloud artifacts repositories list --location=us-central1 --format="table(REPOSITORY,FORMAT,LOCATION)" 2>/dev/null | tail -n +2else    check_pass "No existing repositories (will be created)"fiecho ""echo "6. Compute Quotas"echo "----------------------------------------"# Check CPU quotaCPU_QUOTA=$(gcloud compute project-info describe --format="value(quotas.filter(metric:CPUS).limit)" 2>/dev/null | head -1)if [ -n "$CPU_QUOTA" ] && [ "$CPU_QUOTA" -ge 8 ]; then    check_pass "CPU quota: $CPU_QUOTA vCPUs (sufficient)"else    check_warn "CPU quota: ${CPU_QUOTA:-unknown} vCPUs"    echo "   Minimum recommended: 8 vCPUs"fiecho ""echo "7. Docker Availability"echo "----------------------------------------"if command -v docker &> /dev/null; then    DOCKER_VERSION=$(docker --version 2>/dev/null)    check_pass "Docker installed: $DOCKER_VERSION"else    check_fail "Docker not found in Cloud Shell"    echo "   Cloud Shell should have Docker pre-installed"fiecho ""echo "8. Required Tools"echo "----------------------------------------"TOOLS=("git" "curl" "psql")for TOOL in "${TOOLS[@]}"; do    if command -v $TOOL &> /dev/null; then        VERSION=$($TOOL --version 2>/dev/null | head -1)        check_pass "$TOOL is installed"    else        check_fail "$TOOL not found"    fidoneecho ""echo "=========================================="echo "Summary"echo "=========================================="echo ""# Count issuesISSUES=0if [ "$CURRENT_PROJECT" != "elevated-module-462113-f0" ]; then ((ISSUES++)); fiif [ -z "$ACCOUNT" ]; then ((ISSUES++)); fiif [ "$BILLING_ENABLED" != "True" ]; then ((ISSUES++)); fiif [ ${#MISSING_APIS[@]} -gt 0 ]; then ((ISSUES++)); fiif [ $ISSUES -eq 0 ]; then    echo -e "${GREEN}‚úì All checks passed!${NC}"    echo ""    echo "Your GCP environment is ready for deployment."    echo ""    echo "Next steps:"    echo "1. Clone repository:"    echo "   git clone https://github.com/Ai-Solutions-Store/YouAndINotAI.git"    echo "2. Navigate to directory:"    echo "   cd YouAndINotAI"    echo "3. Checkout branch:"    echo "   git checkout claude/env-configuration-update-011CUKA3csdQegERzxd2r4RA"    echo "4. Run deployment:"    echo "   chmod +x deploy-gcp.sh && ./deploy-gcp.sh"else    echo -e "${YELLOW}‚ö† Found $ISSUES issue(s) that need attention${NC}"    echo ""    echo "Please fix the issues above before deploying."fiecho ""echo "=========================================="echo "Quick Reference Links"echo "=========================================="echo "Console: https://console.cloud.google.com/home/dashboard?project=$CURRENT_PROJECT"echo "Billing: https://console.cloud.google.com/billing?project=$CURRENT_PROJECT"echo "APIs: https://console.cloud.google.com/apis/dashboard?project=$CURRENT_PROJECT"echo "Cloud Run: https://console.cloud.google.com/run?project=$CURRENT_PROJECT"echo "Cloud SQL: https://console.cloud.google.com/sql?project=$CURRENT_PROJECT"echo ""